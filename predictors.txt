predictors (5 anos de histórico, XAUUSD)

predictors_1 - M10, csv_o_M10_2018-01-02_2023-09-15:
01 - OHLC, n_steps = 2, n_hidden_layers = 1 ok
02 - OHLC, n_steps = 2, n_hidden_layers = 2 ok
03 - OHLC, n_steps = 2, n_hidden_layers = 3 ok

04 - OHLC, n_steps = 4, n_hidden_layers = 1 ok
05 - OHLC, n_steps = 4, n_hidden_layers = 2 ok
06 - OHLC, n_steps = 4, n_hidden_layers = 3 ok

07 - OHLC, n_steps = 6, n_hidden_layers = 1 ok
08 - OHLC, n_steps = 6, n_hidden_layers = 2 ok
09 - OHLC, n_steps = 6, n_hidden_layers = 3 ok

10 - OHLC, n_steps = 8, n_hidden_layers = 1 ok
11 - OHLC, n_steps = 8, n_hidden_layers = 2 ok
12 - OHLC, n_steps = 8, n_hidden_layers = 3 -

13 - OHLC, n_steps = 10, n_hidden_layers = 1
14 - OHLC, n_steps = 10, n_hidden_layers = 2
15 - OHLC, n_steps = 10, n_hidden_layers = 3

16 - OHLC, n_steps = 12, n_hidden_layers = 1
17 - OHLC, n_steps = 12, n_hidden_layers = 2
18 - OHLC, n_steps = 12, n_hidden_layers = 3

19 - OHLC, n_steps = 14, n_hidden_layers = 1
20 - OHLC, n_steps = 14, n_hidden_layers = 2
21 - OHLC, n_steps = 14, n_hidden_layers = 3

22 - OHLC, n_steps = 16, n_hidden_layers = 1
23 - OHLC, n_steps = 16, n_hidden_layers = 2
24 - OHLC, n_steps = 16, n_hidden_layers = 3

------

predictors_2 - M10, csv_o_M10_2018-01-02_2023-09-15:
01 - OHLCV, n_steps = 2, n_hidden_layers = 1 ok
02 - OHLCV, n_steps = 2, n_hidden_layers = 2 ok
03 - OHLCV, n_steps = 2, n_hidden_layers = 3 ok

04 - OHLCV, n_steps = 4, n_hidden_layers = 1 ok
05 - OHLCV, n_steps = 4, n_hidden_layers = 2 ok
06 - OHLCV, n_steps = 4, n_hidden_layers = 3 ok

07 - OHLCV, n_steps = 6, n_hidden_layers = 1 ok
08 - OHLCV, n_steps = 6, n_hidden_layers = 2 ok
09 - OHLCV, n_steps = 6, n_hidden_layers = 3 ok

10 - OHLCV, n_steps = 8, n_hidden_layers = 1 ok
11 - OHLCV, n_steps = 8, n_hidden_layers = 2 ok
12 - OHLCV, n_steps = 8, n_hidden_layers = 3

13 - OHLCV, n_steps = 10, n_hidden_layers = 1
14 - OHLCV, n_steps = 10, n_hidden_layers = 2
15 - OHLCV, n_steps = 10, n_hidden_layers = 3

16 - OHLCV, n_steps = 12, n_hidden_layers = 1
17 - OHLCV, n_steps = 12, n_hidden_layers = 2
18 - OHLCV, n_steps = 12, n_hidden_layers = 3

19 - OHLCV, n_steps = 14, n_hidden_layers = 1
20 - OHLCV, n_steps = 14, n_hidden_layers = 2
21 - OHLCV, n_steps = 14, n_hidden_layers = 3

22 - OHLCV, n_steps = 16, n_hidden_layers = 1
23 - OHLCV, n_steps = 16, n_hidden_layers = 2
24 - OHLCV, n_steps = 16, n_hidden_layers = 3


    n_steps = 2, 4, 6, 8, 10, 12, 14, 16
    n_hidden_layers = 1, 2, 3

    M10, csv_o_M10_2018-01-02_2023-09-15:
    n_samples_train = 199000

    validation_split = 0.2
    n_samples_test = 3000
    # horizontally stack columns
    dataset_train = prepare_train_data2(hist, symbol_out, 0, n_samples_train, candle_input_type, candle_output_type)

    # convert into input/output samples
    X_train, y_train = split_sequences2(dataset_train, n_steps, candle_output_type)

    # We are now ready to fit a 1D CNN model on this data, specifying the expected number of time steps and
    # features to expect for each input sample.
    n_features = X_train.shape[2]
    n_inputs = n_steps * n_features

    até n_steps=8, nhl=1:
    max_n_epochs = 100, patience = 3 e 9

    a partir de n_steps=8, nhl=2:
    max_n_epochs = 150, patience = 5 e 15

    n_symbols = len(hist.symbols)

    print(f'symbols = {hist.symbols}')
    print(f'n_symbols = {n_symbols}, n_features (n_cols) = {n_features}, n_steps = {n_steps}, n_inputs = {n_inputs}, '
          f'n_hidden_layers = {n_hidden_layers},\ntipo_vela_entrada = {candle_input_type}, '
          f'tipo_vela_saída = {candle_output_type}, n_samples_train = {n_samples_train}, '
          f'\nvalidation_split = {validation_split}, max_n_epochs = {max_n_epochs}, patience = {patience}')

    model = Sequential()
    n_filters = n_features
    kernel_size = n_steps
    pool_size = n_inputs
    n_neurons = n_inputs

    # define cnn model
    # input layer
    model.add(Conv1D(filters=n_filters, kernel_size=kernel_size, activation='relu', input_shape=(n_steps, n_features)))
    model.add(MaxPooling1D(pool_size=pool_size, padding='same'))
    model.add(Flatten())

    # hidden layers
    for i in range(n_hidden_layers):
        model.add(Dense(n_neurons, activation='relu'))

    # define MLP model
    # n_input = X_train.shape[1] * X_train.shape[2]
    # X_train = X_train.reshape((X_train.shape[0], n_input))
    # model.add(Dense(n_inputs, activation='relu', input_dim=n_input))
    # model.add(Dense(n_inputs, activation='relu'))

    # output layer
    model.add(Dense(len(candle_output_type)))
    model.compile(optimizer='adam', loss='mse')
    model_config = model.get_config()
