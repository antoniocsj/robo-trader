predictors (5 anos de histórico, XAUUSD)

predictors_01:
01 - OHLC, n_steps = 02, n_hidden_layers = 1 ok
02 - OHLC, n_steps = 02, n_hidden_layers = 2 ok
03 - OHLC, n_steps = 02, n_hidden_layers = 3 ok

04 - OHLC, n_steps = 04, n_hidden_layers = 1 ok
05 - OHLC, n_steps = 04, n_hidden_layers = 2 ok
06 - OHLC, n_steps = 04, n_hidden_layers = 3 ok

07 - OHLC, n_steps = 06, n_hidden_layers = 1 ok
08 - OHLC, n_steps = 06, n_hidden_layers = 2 ok
09 - OHLC, n_steps = 06, n_hidden_layers = 3 ok

10 - OHLC, n_steps = 08, n_hidden_layers = 1 -
11 - OHLC, n_steps = 08, n_hidden_layers = 2
12 - OHLC, n_steps = 08, n_hidden_layers = 3

13 - OHLC, n_steps = 10, n_hidden_layers = 1
14 - OHLC, n_steps = 10, n_hidden_layers = 2
15 - OHLC, n_steps = 10, n_hidden_layers = 3

16 - OHLC, n_steps = 12, n_hidden_layers = 1
17 - OHLC, n_steps = 12, n_hidden_layers = 2
18 - OHLC, n_steps = 12, n_hidden_layers = 3

19 - OHLC, n_steps = 14, n_hidden_layers = 1
20 - OHLC, n_steps = 14, n_hidden_layers = 2
21 - OHLC, n_steps = 14, n_hidden_layers = 3

22 - OHLC, n_steps = 16, n_hidden_layers = 1
23 - OHLC, n_steps = 16, n_hidden_layers = 2
24 - OHLC, n_steps = 16, n_hidden_layers = 3

------
predictors_02:
01 - OHLCV, n_steps = 02, n_hidden_layers = 1
02 - OHLCV, n_steps = 02, n_hidden_layers = 2
03 - OHLCV, n_steps = 02, n_hidden_layers = 3

04 - OHLCV, n_steps = 04, n_hidden_layers = 1
05 - OHLCV, n_steps = 04, n_hidden_layers = 2
06 - OHLCV, n_steps = 04, n_hidden_layers = 3

07 - OHLCV, n_steps = 06, n_hidden_layers = 1
08 - OHLCV, n_steps = 06, n_hidden_layers = 2
09 - OHLCV, n_steps = 06, n_hidden_layers = 3

10 - OHLCV, n_steps = 08, n_hidden_layers = 1
11 - OHLCV, n_steps = 08, n_hidden_layers = 2
12 - OHLCV, n_steps = 08, n_hidden_layers = 3

13 - OHLCV, n_steps = 10, n_hidden_layers = 1
14 - OHLCV, n_steps = 10, n_hidden_layers = 2
15 - OHLCV, n_steps = 10, n_hidden_layers = 3

16 - OHLCV, n_steps = 12, n_hidden_layers = 1
17 - OHLCV, n_steps = 12, n_hidden_layers = 2
18 - OHLCV, n_steps = 12, n_hidden_layers = 3

19 - OHLCV, n_steps = 14, n_hidden_layers = 1
20 - OHLCV, n_steps = 14, n_hidden_layers = 2
21 - OHLCV, n_steps = 14, n_hidden_layers = 3

22 - OHLCV, n_steps = 16, n_hidden_layers = 1
23 - OHLCV, n_steps = 16, n_hidden_layers = 2
24 - OHLCV, n_steps = 16, n_hidden_layers = 3

    n_steps = 2, 4, 6, 8, 10, 12
    n_hidden_layers = 1, 2, 3
    n_samples_train = 199000  # Número de amostras usadas na fase de treinamento e validação
    validation_split = 0.2
    n_samples_test = 3000  # Número de amostras usadas na fase de avaliação. São amostras inéditas.
    # horizontally stack columns
    dataset_train = prepare_train_data2(hist, symbol_out, 0, n_samples_train, candle_input_type, candle_output_type)

    # convert into input/output samples
    X_train, y_train = split_sequences2(dataset_train, n_steps, candle_output_type)

    # We are now ready to fit a 1D CNN model on this data, specifying the expected number of time steps and
    # features to expect for each input sample.
    n_features = X_train.shape[2]
    n_inputs = n_steps * n_features
    max_n_epochs = n_inputs * 3 * 0 + 100
    patience = int(max_n_epochs / 10) * 0 + 3
    n_symbols = len(hist.symbols)

    print(f'symbols = {hist.symbols}')
    print(f'n_symbols = {n_symbols}, n_features (n_cols) = {n_features}, n_steps = {n_steps}, n_inputs = {n_inputs}, '
          f'n_hidden_layers = {n_hidden_layers},\ntipo_vela_entrada = {candle_input_type}, '
          f'tipo_vela_saída = {candle_output_type}, n_samples_train = {n_samples_train}, '
          f'\nvalidation_split = {validation_split}, max_n_epochs = {max_n_epochs}, patience = {patience}')

    model = Sequential()
    n_filters = n_features
    kernel_size = n_steps
    pool_size = n_inputs
    n_neurons = n_inputs

    # define cnn model
    # input layer
    model.add(Conv1D(filters=n_filters, kernel_size=kernel_size, activation='relu', input_shape=(n_steps, n_features)))
    model.add(MaxPooling1D(pool_size=pool_size, padding='same'))
    model.add(Flatten())

    # hidden layers
    for i in range(n_hidden_layers):
        model.add(Dense(n_neurons, activation='relu'))

    # define MLP model
    # n_input = X_train.shape[1] * X_train.shape[2]
    # X_train = X_train.reshape((X_train.shape[0], n_input))
    # model.add(Dense(n_inputs, activation='relu', input_dim=n_input))
    # model.add(Dense(n_inputs, activation='relu'))

    # output layer
    model.add(Dense(len(candle_output_type)))
    model.compile(optimizer='adam', loss='mse')
    model_config = model.get_config()
